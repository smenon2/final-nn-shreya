{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a73a563-754f-4f60-8007-a2621bf62576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the dependencies\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from nn import nn, io, preprocess\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda503e8-afb9-4c6b-8071-6e621663a854",
   "metadata": {},
   "source": [
    "I will first read in the data. We then have to make the negative examples the same sequence lengths as the positive examples. All of the positive examples have 17bp so I'll just loop through the negative sequences and create 17bp sub-sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a5ee693-ebe2-4904-a4ea-c71548443454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive examples: 137\n",
      "Negative examples: 183296\n"
     ]
    }
   ],
   "source": [
    "positives = io.read_text_file(\"data/rap1-lieb-positives.txt\")\n",
    "negatives = io.read_fasta_file(\"data/yeast-upstream-1k-negative.fa\")\n",
    "\n",
    "\n",
    "# Make the negative sequences the same length as the positive sequences \n",
    "# We see that each of the positive sequences is 17bp \n",
    "\n",
    "seq_length = len(positives[0])\n",
    "negative_trimmed = []\n",
    "for s in negatives:\n",
    "    seq = str()\n",
    "    for i in range(len(s)):\n",
    "        seq = seq + s[i] \n",
    "        \n",
    "        if i > 0 and i % seq_length == 0:\n",
    "            negative_trimmed.append(seq)\n",
    "            seq = str()\n",
    "    \n",
    "# Combine and create labels\n",
    "sequences = positives + negative_trimmed\n",
    "labels = [True] * len(positives) + [False] * len(negative_trimmed)\n",
    "\n",
    "# ensure each example has proper number of base pairs\n",
    "sequences = [s[:seq_length] for s in sequences]\n",
    "\n",
    "# Print counts\n",
    "print(\"Positive examples:\", len(positives))\n",
    "print(\"Negative examples:\", len(negative_trimmed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dd09a4-60cb-4bc1-9315-e556b07f0ebe",
   "metadata": {},
   "source": [
    "We then see that we have to subsample such that we equal number of examples for both positive and negative sequences. I chose to implement a function that upsamples the smaller class. I think this makes sense here because there are so few positive examples - so if I were to downsample the bigger class, there would be too few examples to train (fewer after splitting between training and validation). This will increase the number of positive examples and overall number of labeled examples available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e3699b-3d13-4e28-8cc1-b0e564a137b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq shapes (366592,)\n",
      "Label shapes (366592,)\n"
     ]
    }
   ],
   "source": [
    "seqs, labels = preprocess.sample_seqs(np.array(sequences), np.array(labels))\n",
    "print(\"Seq shapes\", seqs.shape)\n",
    "print(\"Label shapes\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670a2810-6aef-49aa-b198-360c643543bb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "Now we will one hot encode the sequences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d62b3564-4fb0-4262-ac44-1517c1e7386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocess.one_hot_encode_seqs(seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e63cda4c-790f-4a47-84f7-41c1e996f026",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 1, 0, 0],\n",
       "       [1, 0, 0, ..., 1, 0, 0],\n",
       "       [1, 0, 0, ..., 1, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa11e609-2524-4e84-bf98-fa6ea5fa8b0d",
   "metadata": {},
   "source": [
    "Now, we can split the data into training and testing sets. I just use the sklearn train_test_split function to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b1aedc-9084-40a6-bfe9-5cf8de42a199",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, np.array(labels), test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c818f2f-c5f3-468e-b1a7-9c4bef7cf3a9",
   "metadata": {},
   "source": [
    "Now, I create a tuning grid with different hyperparameter values. I will loop through all of the different combinations, fit a model and then select the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adce4402-a6e1-448e-8fa8-c4ae2496ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = [1e-4, 1e-5, 1e-6]\n",
    "batch_grid = [10, 50, 500]\n",
    "epochs_grid = [5, 10, 20]\n",
    "\n",
    "comb_array = np.array(np.meshgrid(lr_grid, batch_grid, epochs_grid)).T.reshape(-1, 3)\n",
    "layers = [{\"input_dim\": 68, \"output_dim\": 34, \"activation\": \"sigmoid\"},\n",
    "          {\"input_dim\": 34, \"output_dim\": 17, \"activation\": \"sigmoid\"},\n",
    "          {\"input_dim\": 17, \"output_dim\": 1, \"activation\": \"sigmoid\"},]\n",
    "\n",
    "# Need to reshape the y values in order to fit through net\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdaa06f-5575-4a25-b0b8-4c6ab427ec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through tune grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779004ee-972c-44ee-9c8b-52b41172cd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "tune_grid = []\n",
    "count = 0\n",
    "for i in comb_array:\n",
    "    count += 1 \n",
    "    lr = i[0]\n",
    "    batch_size = i[1]\n",
    "    epochs = int(i[2])\n",
    "    net = nn.NeuralNetwork(layers, lr = lr, seed = 42, batch_size = batch_size, epochs = epochs, loss_function = \"bce\")\n",
    "    train_losses, val_losses = net.fit(X_train, y_train, X_test, y_test)\n",
    "    # We want to save the test loss for the last epoch\n",
    "    test_loss = val_losses[-1]\n",
    "    tune_grid.append([lr, batch_size, epochs, test_loss])\n",
    "    if count % 2 == 0 :\n",
    "        print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c83f3b-bf96-4b80-a06f-8836b503734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.NeuralNetwork(layers, lr = 0.001, seed = 42, batch_size = 10, epochs = 5, loss_function = \"bce\")\n",
    "train_losses, val_losses = net.fit(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84118050-f7ff-43a2-a7ef-19eca18c5734",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses)\n",
    "plt.title(\"Training Losses per epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a58f81-bbd4-4a4e-bef2-299821491450",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(val_losses)\n",
    "plt.title(\"Validation Losses per epoch\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144e76ff-dc49-4b8b-a9d3-fef5e30529c0",
   "metadata": {},
   "source": [
    "We can also calculate the validation accuracy of the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b025e-7d5e-4f34-bd7d-ba9205735efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (net.predict(X_val) >= 0.5).astype(int)\n",
    "accuracy = np.sum(pred == y_val) / len(y_val)\n",
    "print(\"Accuracy:\", accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e51a1-15dd-45a1-ad14-84392570a230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a45d08-ac07-4ba8-88a8-7147a33a91dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291dfc60-982e-48a0-958f-36976ece0613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9562b1e-def6-4e8a-9dec-ce2c69bcdccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa6729-e14a-4302-b8b2-590368402ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e253f-82bb-4e27-bc42-235f3e56ee87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa8ced-b2d0-43f3-b54e-4391d043475a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c545f1c7-477e-493d-9b9a-d7e3f74df6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4baf8b-94bc-45e5-8683-89ee0533f580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e2188a-cbad-47f3-a544-a02954b55d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26996d-d48d-45d8-8304-1a84c2eac04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d01e5f-dcd1-4a7a-bc77-7a026ba2e517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd212d5-f7eb-4f6a-a999-a87693d9de77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef818236-bd14-467d-8dd2-20b5013b09e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5416974-f742-4095-aa37-39907176abdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3930c8-7827-49a4-943a-e43763825b68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:BMI203]",
   "language": "python",
   "name": "conda-env-BMI203-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
